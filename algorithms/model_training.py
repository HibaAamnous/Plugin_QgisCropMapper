# -*- coding: utf-8 -*-
"""
Algorithme d'entra√Ænement des mod√®les de Machine Learning
"""

import os
import matplotlib
matplotlib.use('Agg') 
import joblib
import numpy as np
import pandas as pd
from datetime import datetime
from sklearn.preprocessing import RobustScaler, LabelEncoder
from sklearn.impute import SimpleImputer 
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV, cross_val_score
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,f1_score
import xgboost as xgb

from qgis.PyQt.QtCore import QCoreApplication
from qgis.core import (
    QgsProcessing, QgsProcessingAlgorithm,
    QgsProcessingParameterVectorLayer, QgsProcessingParameterField,
    QgsProcessingParameterEnum, QgsProcessingParameterBoolean,
    QgsProcessingParameterFileDestination, QgsProcessingParameterFolderDestination,
    QgsProcessingException
)

from ..utils.ml_utils import prepare_training_data, evaluate_model, save_model_report
from ..utils.ml_utils import validate_training_data  

class ModelTrainingAlgorithm(QgsProcessingAlgorithm):
    """Algorithme d'entra√Ænement des mod√®les ML"""
    
    INPUT_SAMPLES = 'INPUT_SAMPLES'
    CULTURE_FIELD = 'CULTURE_FIELD'
    ALGORITHMS = 'ALGORITHMS'
    OPTIMIZE_HYPERPARAMS = 'OPTIMIZE_HYPERPARAMS'
    OUTPUT_MODEL = 'OUTPUT_MODEL'
    OUTPUT_REPORT_DIR = 'OUTPUT_REPORT_DIR'

    def initAlgorithm(self, config=None):
        """Initialize algorithm parameters"""
        
        self.addParameter(
            QgsProcessingParameterVectorLayer(
                self.INPUT_SAMPLES,
                self.tr('√âchantillons d\'entra√Ænement'),
                [QgsProcessing.TypeVectorPoint]
            )
        )
        self.addParameter(
            QgsProcessingParameterField(
                self.CULTURE_FIELD,
                self.tr('Champ des types de cultures'),
                parentLayerParameterName=self.INPUT_SAMPLES,
                type=QgsProcessingParameterField.String
            )
        )
        algorithm_options = [
            'Random Forest',
            'SVM',
            'XGBoost',
            'Decision Tree',
            'Tous les algorithmes'
        ]
        self.addParameter(
            QgsProcessingParameterEnum(
                self.ALGORITHMS,
                self.tr('Algorithmes de Machine Learning'),
                options=algorithm_options,
                allowMultiple=True,
                defaultValue=[0, 2, 4]  
            )
        )
        
        self.addParameter(
            QgsProcessingParameterBoolean(
                self.OPTIMIZE_HYPERPARAMS,
                self.tr('Optimiser les hyperparam√®tres (plus lent mais meilleur)'),
                defaultValue=True
            )
        )
        
        self.addParameter(
            QgsProcessingParameterFileDestination(
                self.OUTPUT_MODEL,
                self.tr('Meilleur mod√®le entra√Æn√©'),
                fileFilter='Pickle files (*.pkl)'
            )
        )

        self.addParameter(
            QgsProcessingParameterFileDestination(
                'OUTPUT_SCALER',
                self.tr('Scaler entra√Æn√©'),
                fileFilter='Pickle files (*.pkl)'
            )
        )
        self.addParameter(
            QgsProcessingParameterFileDestination(
                'OUTPUT_LABEL_ENCODER',
                self.tr('Label Encoder entra√Æn√©'),
                fileFilter='Pickle files (*.pkl)'
            )
        )
        
        self.addParameter(
            QgsProcessingParameterFolderDestination(
                self.OUTPUT_REPORT_DIR,
                self.tr('Dossier des rapports d\'√©valuation')
            )
        )

    def processAlgorithm(self, parameters, context, feedback):
        """Process algorithm"""
        samples_layer = self.parameterAsVectorLayer(parameters, self.INPUT_SAMPLES, context)
        culture_field = self.parameterAsString(parameters, self.CULTURE_FIELD, context)
        algorithm_indices = self.parameterAsEnums(parameters, self.ALGORITHMS, context)
        optimize_hyperparams = self.parameterAsBool(parameters, self.OPTIMIZE_HYPERPARAMS, context)
        output_model_path = self.parameterAsFileOutput(parameters, self.OUTPUT_MODEL, context)
        output_scaler_path = self.parameterAsFileOutput(parameters, 'OUTPUT_SCALER', context)
        output_label_encoder_path = self.parameterAsFileOutput(parameters, 'OUTPUT_LABEL_ENCODER', context)
        report_dir = self.parameterAsString(parameters, self.OUTPUT_REPORT_DIR, context)
        
        feedback.pushInfo("="*60)
        feedback.pushInfo("ENTRA√éNEMENT DES MOD√àLES DE MACHINE LEARNING")
        feedback.pushInfo("="*60)
        
        try:
            feedback.pushInfo("Pr√©paration des donn√©es d'entra√Ænement...")
            X_train, X_test, y_train, y_test, feature_names, class_names = prepare_training_data(
                samples_layer, culture_field, feedback
            )
            if len(feature_names) == 0 or X_train.shape[1] == 0:
                raise QgsProcessingException(
                    "Aucune caract√©ristique trouv√©e dans les √©chantillons. "
                    "Assurez-vous que votre shapefile contient les bandes spectrales comme attributs.(band_1,band_2...) "
                    "Utilisez l'outil 'Pr√©paration des Echantillons' pour extraire les valeurs des bandes."
                )
            feedback.pushInfo("Application du preprocessing...")
            imputer = SimpleImputer(strategy='mean') 
            X_train = imputer.fit_transform(X_train)
            X_test = imputer.transform(X_test)

            scaler = RobustScaler()
            scaler.fit(X_train)
            X_train = scaler.transform(X_train)
            X_test = scaler.transform(X_test)
            label_encoder = LabelEncoder()
            label_encoder.fit(y_train)
            y_train = label_encoder.transform(y_train)
            y_test = label_encoder.transform(y_test)
            class_names = label_encoder.classes_ 
            if not validate_training_data(X_train, y_train, feature_names, class_names, feedback):  
                raise QgsProcessingException("Validation des donn√©es √©chou√©e. V√©rifiez les √©chantillons.")
            feedback.pushInfo(f"‚úì Donn√©es pr√©par√©es:")
            feedback.pushInfo(f"  - √âchantillons d'entra√Ænement: {len(X_train)}")
            feedback.pushInfo(f"  - √âchantillons de test: {len(X_test)}")
            feedback.pushInfo(f"  - Caract√©ristiques: {len(feature_names)}")
            feedback.pushInfo(f"  - Classes: {len(class_names)} ({', '.join(class_names)})")
            
            algorithms_to_train = self._get_algorithms_to_train(algorithm_indices)
            feedback.pushInfo(f"Algorithmes s√©lectionn√©s: {', '.join(algorithms_to_train.keys())}")

            trained_models = {}
            model_scores = {}
            
            for name, (model_class, params) in algorithms_to_train.items():
                feedback.pushInfo(f"\n--- Entra√Ænement: {name} ---")
                
                try:
                    if optimize_hyperparams and params:
                        feedback.pushInfo("Optimisation des hyperparam√®tres...")
                        model = GridSearchCV(
                            model_class(),
                            params,
                            cv=3,
                            scoring='f1_weighted',
                            n_jobs=-1,
                            verbose=1
                        )
                        model.fit(X_train, y_train)
                        feedback.pushInfo(f"‚úì Meilleurs param√®tres: {model.best_params_}")
                        best_model = model.best_estimator_
                    else:
                        feedback.pushInfo("Entra√Ænement avec param√®tres par d√©faut...")
                        best_model = model_class()
                        best_model.fit(X_train, y_train)
                    
                    y_train_pred = best_model.predict(X_train) 
                    train_score = f1_score(y_train, y_train_pred, average='weighted') 

                    y_test_pred = best_model.predict(X_test) 
                    test_score = f1_score(y_test, y_test_pred, average='weighted')

                    cv_scores = cross_val_score(best_model, X_train, y_train, cv=5, scoring='f1_weighted')  
                    feedback.pushInfo(f"‚úì F1 Score d'entra√Ænement: {train_score:.4f}") 
                    feedback.pushInfo(f"‚úì F1 Score de test: {test_score:.4f}")
                    feedback.pushInfo(f"‚úì Validation crois√©e (F1): {cv_scores.mean():.4f} (¬±{cv_scores.std()*2:.4f})")

                    trained_models[name] = best_model
                    model_scores[name] = {
                        'train_score': train_score,
                        'test_score': test_score,
                        'cv_mean': cv_scores.mean(),
                        'cv_std': cv_scores.std()
                    }

                    model_path = os.path.join(report_dir, f"{name.lower().replace(' ', '_')}_model.pkl")
                    joblib.dump(trained_models[name], model_path)
                    feedback.pushInfo(f"‚úì Mod√®le {name} sauvegard√©: {model_path}")
                    
                except Exception as e:
                    feedback.pushInfo(f"‚ùå Erreur avec {name}: {str(e)}")
                    continue
            
            if not trained_models:
                raise QgsProcessingException("Aucun mod√®le n'a pu √™tre entra√Æn√© avec succ√®s")
            

            best_model_name = max(model_scores.keys(), key=lambda k: model_scores[k]['test_score'])
            best_model = trained_models[best_model_name]
            best_score = model_scores[best_model_name]['test_score']

            feedback.pushInfo(f"\nüèÜ Meilleur mod√®le: {best_model_name} (Score: {best_score:.4f})")
            model_data = {
                'model': best_model,
                'feature_names': feature_names,
                'class_names': class_names 
            }
            joblib.dump(model_data, output_model_path)  
            joblib.dump(scaler, output_scaler_path)  
            joblib.dump(label_encoder, output_label_encoder_path) 

            feedback.pushInfo(f"‚úì Meilleur mod√®le sauvegard√©: {output_model_path}")
            feedback.pushInfo(f"‚úì Scaler sauvegard√©: {output_scaler_path}")
            feedback.pushInfo(f"‚úì Label Encoder sauvegard√©: {output_label_encoder_path}")

            feedback.pushInfo("\nG√©n√©ration des rapports d'√©valuation...")
            self._generate_evaluation_reports(
                trained_models, model_scores, X_test, y_test, 
                class_names, report_dir, feedback
            )
            
            feedback.pushInfo("="*60)
            feedback.pushInfo("ENTRA√éNEMENT TERMIN√â AVEC SUCC√àS")
            feedback.pushInfo("="*60)
            
            return {
                self.OUTPUT_MODEL: output_model_path,
                self.OUTPUT_REPORT_DIR: report_dir
            }
            
        except Exception as e:
            feedback.pushInfo(f"ERREUR: {str(e)}")
            raise QgsProcessingException(str(e))
        

    def _get_algorithms_to_train(self, algorithm_indices):
        """Get algorithms to train based on selection"""
        
        all_algorithms = {
            'Random Forest': (
                RandomForestClassifier,
                {
                    'n_estimators': [10, 25, 50, 100],
                    'criterion': ['gini', 'entropy'],
                    'max_depth': [5, 10, 15, 20, 25, None],
                    'min_samples_leaf': [1, 2, 5, 10],
                    'random_state': [1]
                }
            ),
            'SVM': (  
                SVC,
                {
                    'C': [0.1, 1, 10, 100],
                    'gamma': [1, 0.1, 0.01, 0.001],
                    'kernel': ['rbf', 'poly'],
                    'probability': [True]
                }
            ),
            'XGBoost': (
                xgb.XGBClassifier,
                {
                    'min_child_weight': [1, 5, 10],
                    'gamma': [0.5, 1, 1.5, 2, 5],
                    'subsample': [0.6, 0.8, 1.0],
                    'colsample_bytree': [0.6, 0.8, 1.0],
                    'max_depth': [3, 4, 5],
                    'random_state': [1]
                }
            ),
            'Decision Tree': (
                DecisionTreeClassifier,
                {
                    'criterion': ['gini', 'entropy'],
                    'max_depth': [None, 5, 10],
                    'min_samples_split': [2, 5, 10],
                    'min_samples_leaf': [1, 2, 5],
                    'random_state': [1]
                }
            )
        }
        
        selected_algorithms = {}
        
        for idx in algorithm_indices:
            if idx == 4:  
                return all_algorithms
            else:
                algo_name = list(all_algorithms.keys())[idx]
                selected_algorithms[algo_name] = all_algorithms[algo_name]
        
        return selected_algorithms

    def _generate_evaluation_reports(self, models, scores, X_test, y_test, class_names, report_dir, feedback):
        """Generate detailed evaluation reports with visualizations"""
        try:
            os.makedirs(report_dir, exist_ok=True)

            comparison_report = os.path.join(report_dir, 'model_comparison.txt')
            with open(comparison_report, 'w', encoding='utf-8') as f:
                f.write("RAPPORT DE COMPARAISON DES MOD√àLES\n")
                f.write("="*50 + "\n\n")
                f.write(f"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"Nombre d'√©chantillons de test: {len(X_test)}\n")
                f.write(f"Nombre de classes: {len(class_names)}\n")
                f.write(f"Classes: {', '.join(class_names)}\n\n")

                f.write("R√âSULTATS PAR MOD√àLE:\n")
                f.write("-" * 80 + "\n")
                f.write(f"{'Mod√®le':<20} {'Train':<10} {'Test':<10} {'CV Mean':<10} {'CV Std':<10}\n")
                f.write("-" * 80 + "\n")
                
                for name, score_data in scores.items():
                    f.write(f"{name:<20} {score_data['train_score']:<10.4f} "
                        f"{score_data['test_score']:<10.4f} {score_data['cv_mean']:<10.4f} "
                        f"{score_data['cv_std']:<10.4f}\n")
                
                f.write("-" * 80 + "\n\n")
                
                best_model_name = max(scores.keys(), key=lambda k: scores[k]['test_score'])
                f.write(f"MEILLEUR MOD√àLE: {best_model_name}\n")
                f.write(f"Score de test: {scores[best_model_name]['test_score']:.4f}\n\n")

            for name, model in models.items():
                feedback.pushInfo(f"G√©n√©ration du rapport pour {name}...")
                
                y_pred = model.predict(X_test)

                evaluation_results = {
                    'accuracy': accuracy_score(y_test, y_pred),
                    'classification_report': classification_report(y_test, y_pred, target_names=class_names, output_dict=True),
                    'confusion_matrix': confusion_matrix(y_test, y_pred),
                    'predictions': y_pred,
                    'true_labels': y_test
                }
                report_path, cm_image_path = save_model_report(
                    model, name, evaluation_results, 
                    self.feature_names, class_names, report_dir 
                )
                
                feedback.pushInfo(f"‚úì Rapport g√©n√©r√©: {os.path.basename(report_path)}")
                feedback.pushInfo(f"‚úì Matrice de confusion: {os.path.basename(cm_image_path)}")
                    
            feedback.pushInfo(f"‚úì Rapports et visualisations g√©n√©r√©s dans: {report_dir}")
            
        except Exception as e:
            feedback.pushInfo(f"‚ùå Erreur lors de la g√©n√©ration des rapports: {str(e)}")
 

    def name(self):
        return 'model_training'

    def displayName(self):
        return self.tr('3 - Entra√Ænement Mod√®les ML')

    def group(self):
        return self.tr('Cartographie des Cultures')

    def groupId(self):
        return 'agriculture_mapping'

    def shortHelpString(self):
        return self.tr("""
        <h3>Entra√Ænement des Mod√®les de Machine Learning</h3>
        <p>Entra√Æne et √©value plusieurs algorithmes de classification pour la cartographie des cultures.</p>
        
        <h4>Algorithmes disponibles:</h4>
        <ul>
        <li><b>Random Forest:</b> Ensemble de arbres de d√©cision</li>
        <li><b>SVM:</b> Machine √† vecteurs de support</li>
        <li><b>XGBoost:</b> Gradient boosting optimis√©</li>
        <li><b>Decision Tree:</b> Arbre de d√©cision simple</li>
        </ul>
        
        <h4>Fonctionnalit√©s:</h4>
        <ul>
        <li><b>Optimisation automatique:</b> GridSearch pour les hyperparam√®tres</li>
        <li><b>Validation crois√©e:</b> √âvaluation robuste des performances</li>
        <li><b>S√©lection automatique:</b> Meilleur mod√®le bas√© sur le f1 score</li>
        <li><b>Rapports d√©taill√©s:</b> M√©triques et matrices de confusion</li>
        </ul>
        
        <h4>Sorties:</h4>
        <ul>
        <li><b>Mod√®le optimal:</b> Fichier .pkl avec le meilleur algorithme</li>
        <li><b>Rapports:</b> √âvaluation compl√®te de tous les mod√®les</li>
        </ul>
        """)

    def tr(self, string):
        return QCoreApplication.translate('Processing', string)

    def icon(self):
        """Return algorithm icon"""
        from ..help_system import HelpSystem
        help_system = HelpSystem(os.path.dirname(os.path.dirname(__file__)))
        return help_system.get_algorithm_icon('model_training')

    def helpUrl(self):
        """Return help URL"""
        from ..help_system import HelpSystem
        help_system = HelpSystem(os.path.dirname(os.path.dirname(__file__)))
        return help_system.get_help_url(self.name())

    def createInstance(self):
        return ModelTrainingAlgorithm()